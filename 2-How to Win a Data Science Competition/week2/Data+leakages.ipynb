{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment we will illustrate a very severe data leakage, that can often be found in competitions, where the pairs of object should be scored, e.g. predict $1$ if two objects belong to the same class and $0$ otherwise. \n",
    "\n",
    "The data in this assignment is taken from a real competition, and the funniest thing is that *we will not use training set at all* and achieve almost 100% accuracy score! We will just exploit the leakage.\n",
    "\n",
    "Now go through the notebook and complete the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the test data. Note, that we don't have any training data here, just test data. Moreover, *we will not even use any features* of test objects. All we need to solve this task is the file with the indices for the pairs, that we need to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data with test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1427</td>\n",
       "      <td>8053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17044</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19237</td>\n",
       "      <td>20966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8005</td>\n",
       "      <td>20765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16837</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3657</td>\n",
       "      <td>12504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2836</td>\n",
       "      <td>7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6136</td>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>23295</td>\n",
       "      <td>9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6621</td>\n",
       "      <td>7672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairId  FirstId  SecondId\n",
       "0       0     1427      8053\n",
       "1       1    17044      7681\n",
       "2       2    19237     20966\n",
       "3       3     8005     20765\n",
       "4       4    16837       599\n",
       "5       5     3657     12504\n",
       "6       6     2836      7582\n",
       "7       7     6136      6111\n",
       "8       8    23295      9817\n",
       "9       9     6621      7672"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../readonly/data_leakages_data/test_pairs.csv')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can think that there is a test dataset of images, and each image is assigned a unique `Id` from $0$ to $N-1$ (N -- is the number of images). In the dataframe from above `FirstId` and `SecondId` point to these `Id`'s and define pairs, that we should compare: e.g. do both images in the pair belong to the same class or not. So, for example for the first row: if images with `Id=1427` and `Id=8053` belong to the same class, we should predict $1$, and $0$ otherwise. \n",
    "\n",
    "But in our case we don't really care about the images, and how exactly we compare the images (as long as comparator is binary).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We suggest you to try to solve the puzzle yourself first.** You need to submit a `.csv` file with columns `pairId` and `Prediction` to the grader. The number of submissions allowed is made pretty huge to let you explore the data without worries. The returned score should be very close to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you do not want to think much** -- scroll down and follow the instructions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and leakage intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already know, the key to discover data leakages is careful EDA. So let's start our work with some basic data exploration and build an intuition about the leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check, how many different `id`s are there: concatenate `FirstId` and `SecondId` and print the number of unique elements. Also print minimum and maximum value for that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in FirstId   26325\n",
      "Number of unique elements in SecondId  26310\n",
      "Shape of test  (368550, 3)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "print('Number of unique elements in FirstId  ', len(test['FirstId'].unique()))\n",
    "print('Number of unique elements in SecondId ', len(test['SecondId'].unique()))\n",
    "print('Shape of test ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['col1'] = test['FirstId'].map(str)  + test['SecondId'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['col2'] = test['SecondId'].map(str) + test['FirstId'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  137\n"
     ]
    }
   ],
   "source": [
    "print('Min: ', min(test['col1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max:  2632426314\n"
     ]
    }
   ],
   "source": [
    "print('Max: ', max(test['col2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.685500e+05\n",
       "mean     5.817458e+08\n",
       "std      6.576371e+08\n",
       "min      1.370000e+02\n",
       "25%      8.574808e+07\n",
       "50%      2.351056e+08\n",
       "75%      9.747112e+08\n",
       "max      2.632312e+09\n",
       "Name: col1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['col1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in Con   368509\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique elements in Con  ', len(test['col1'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    368550.000000\n",
       "mean      10863.601118\n",
       "std        7280.190939\n",
       "min           0.000000\n",
       "25%        4574.000000\n",
       "50%        9886.000000\n",
       "75%       16512.000000\n",
       "max       26324.000000\n",
       "Name: FirstId, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['FirstId'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    368550.000000\n",
       "mean      11950.398882\n",
       "std        7602.814820\n",
       "min           0.000000\n",
       "25%        5698.000000\n",
       "50%       10512.000000\n",
       "75%       18782.000000\n",
       "max       26324.000000\n",
       "Name: SecondId, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['SecondId'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then print how many pairs we need to classify (it is basically the number of rows in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique in Con 368509\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique in Con', len(test['col1'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print, how many distinct pairs it would be possible to create out of all \"images\" in the dataset?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct pairs =  692610750\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "print('Number of distinct pairs = ', len(test['FirstId'].unique())*len(test['SecondId'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the number of pairs we are given to classify is very very small compared to the total number of pairs. \n",
    "\n",
    "To exploit the leak we need to **assume (or prove)**, that the total number of positive pairs is small, compared to the total number of pairs. For example: think about an image dataset with $1000$ classes, $N$ images per class. Then if the task was to tell whether a pair of images belongs to the same class or not, we would have $1000\\frac{N(N-1)}{2}$ positive pairs, while total number of pairs was $\\frac{1000N(1000N - 1)}{2}$.\n",
    "\n",
    "Another example: in [Quora competitition](https://www.kaggle.com/c/quora-question-pairs) the task was to classify whether a pair of qustions are duplicates of each other or not. Of course, total number of question pairs is very huge, while number of duplicates (positive pairs) is much much smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, let's get a fraction of pairs of class `1`. We just need to submit a constant prediction \"all ones\" and check the returned accuracy. Create a dataframe with columns `pairId` and `Prediction`, fill it and export it to `.csv` file. Then submit to grader and examine grader's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93524</th>\n",
       "      <td>93524</td>\n",
       "      <td>2255</td>\n",
       "      <td>18014</td>\n",
       "      <td>225518014</td>\n",
       "      <td>180142255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107647</th>\n",
       "      <td>107647</td>\n",
       "      <td>10008</td>\n",
       "      <td>10404</td>\n",
       "      <td>1000810404</td>\n",
       "      <td>1040410008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123152</th>\n",
       "      <td>123152</td>\n",
       "      <td>3505</td>\n",
       "      <td>8046</td>\n",
       "      <td>35058046</td>\n",
       "      <td>80463505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123761</th>\n",
       "      <td>123761</td>\n",
       "      <td>19</td>\n",
       "      <td>16150</td>\n",
       "      <td>1916150</td>\n",
       "      <td>1615019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124261</th>\n",
       "      <td>124261</td>\n",
       "      <td>5641</td>\n",
       "      <td>8046</td>\n",
       "      <td>56418046</td>\n",
       "      <td>80465641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124903</th>\n",
       "      <td>124903</td>\n",
       "      <td>6107</td>\n",
       "      <td>235</td>\n",
       "      <td>6107235</td>\n",
       "      <td>2356107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128879</th>\n",
       "      <td>128879</td>\n",
       "      <td>17602</td>\n",
       "      <td>2717</td>\n",
       "      <td>176022717</td>\n",
       "      <td>271717602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133284</th>\n",
       "      <td>133284</td>\n",
       "      <td>1591</td>\n",
       "      <td>8217</td>\n",
       "      <td>15918217</td>\n",
       "      <td>82171591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139487</th>\n",
       "      <td>139487</td>\n",
       "      <td>504</td>\n",
       "      <td>2799</td>\n",
       "      <td>5042799</td>\n",
       "      <td>2799504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153763</th>\n",
       "      <td>153763</td>\n",
       "      <td>699</td>\n",
       "      <td>2994</td>\n",
       "      <td>6992994</td>\n",
       "      <td>2994699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171167</th>\n",
       "      <td>171167</td>\n",
       "      <td>5494</td>\n",
       "      <td>996</td>\n",
       "      <td>5494996</td>\n",
       "      <td>9965494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173304</th>\n",
       "      <td>173304</td>\n",
       "      <td>2741</td>\n",
       "      <td>6405</td>\n",
       "      <td>27416405</td>\n",
       "      <td>64052741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194281</th>\n",
       "      <td>194281</td>\n",
       "      <td>24996</td>\n",
       "      <td>699</td>\n",
       "      <td>24996699</td>\n",
       "      <td>69924996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201838</th>\n",
       "      <td>201838</td>\n",
       "      <td>765</td>\n",
       "      <td>18823</td>\n",
       "      <td>76518823</td>\n",
       "      <td>18823765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212235</th>\n",
       "      <td>212235</td>\n",
       "      <td>1460</td>\n",
       "      <td>14578</td>\n",
       "      <td>146014578</td>\n",
       "      <td>145781460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226778</th>\n",
       "      <td>226778</td>\n",
       "      <td>1980</td>\n",
       "      <td>8046</td>\n",
       "      <td>19808046</td>\n",
       "      <td>80461980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229354</th>\n",
       "      <td>229354</td>\n",
       "      <td>2540</td>\n",
       "      <td>3795</td>\n",
       "      <td>25403795</td>\n",
       "      <td>37952540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238033</th>\n",
       "      <td>238033</td>\n",
       "      <td>1420</td>\n",
       "      <td>8046</td>\n",
       "      <td>14208046</td>\n",
       "      <td>80461420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239980</th>\n",
       "      <td>239980</td>\n",
       "      <td>2627</td>\n",
       "      <td>10404</td>\n",
       "      <td>262710404</td>\n",
       "      <td>104042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244528</th>\n",
       "      <td>244528</td>\n",
       "      <td>9217</td>\n",
       "      <td>353</td>\n",
       "      <td>9217353</td>\n",
       "      <td>3539217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245781</th>\n",
       "      <td>245781</td>\n",
       "      <td>22953</td>\n",
       "      <td>819</td>\n",
       "      <td>22953819</td>\n",
       "      <td>81922953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247753</th>\n",
       "      <td>247753</td>\n",
       "      <td>2094</td>\n",
       "      <td>8160</td>\n",
       "      <td>20948160</td>\n",
       "      <td>81602094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256914</th>\n",
       "      <td>256914</td>\n",
       "      <td>332</td>\n",
       "      <td>10404</td>\n",
       "      <td>33210404</td>\n",
       "      <td>10404332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268567</th>\n",
       "      <td>268567</td>\n",
       "      <td>15193</td>\n",
       "      <td>604</td>\n",
       "      <td>15193604</td>\n",
       "      <td>60415193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277229</th>\n",
       "      <td>277229</td>\n",
       "      <td>7</td>\n",
       "      <td>7323</td>\n",
       "      <td>77323</td>\n",
       "      <td>73237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277387</th>\n",
       "      <td>277387</td>\n",
       "      <td>2061</td>\n",
       "      <td>23019</td>\n",
       "      <td>206123019</td>\n",
       "      <td>230192061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280690</th>\n",
       "      <td>280690</td>\n",
       "      <td>6957</td>\n",
       "      <td>10404</td>\n",
       "      <td>695710404</td>\n",
       "      <td>104046957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282925</th>\n",
       "      <td>282925</td>\n",
       "      <td>1223</td>\n",
       "      <td>7915</td>\n",
       "      <td>12237915</td>\n",
       "      <td>79151223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289264</th>\n",
       "      <td>289264</td>\n",
       "      <td>2563</td>\n",
       "      <td>2171</td>\n",
       "      <td>25632171</td>\n",
       "      <td>21712563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289966</th>\n",
       "      <td>289966</td>\n",
       "      <td>29</td>\n",
       "      <td>25009</td>\n",
       "      <td>2925009</td>\n",
       "      <td>2500929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291945</th>\n",
       "      <td>291945</td>\n",
       "      <td>4213</td>\n",
       "      <td>221</td>\n",
       "      <td>4213221</td>\n",
       "      <td>2214213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300074</th>\n",
       "      <td>300074</td>\n",
       "      <td>2241</td>\n",
       "      <td>9618</td>\n",
       "      <td>22419618</td>\n",
       "      <td>96182241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307799</th>\n",
       "      <td>307799</td>\n",
       "      <td>14231</td>\n",
       "      <td>9079</td>\n",
       "      <td>142319079</td>\n",
       "      <td>907914231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309351</th>\n",
       "      <td>309351</td>\n",
       "      <td>5805</td>\n",
       "      <td>684</td>\n",
       "      <td>5805684</td>\n",
       "      <td>6845805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310044</th>\n",
       "      <td>310044</td>\n",
       "      <td>6291</td>\n",
       "      <td>10404</td>\n",
       "      <td>629110404</td>\n",
       "      <td>104046291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330339</th>\n",
       "      <td>330339</td>\n",
       "      <td>4155</td>\n",
       "      <td>10404</td>\n",
       "      <td>415510404</td>\n",
       "      <td>104044155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336355</th>\n",
       "      <td>336355</td>\n",
       "      <td>2288</td>\n",
       "      <td>16120</td>\n",
       "      <td>228816120</td>\n",
       "      <td>161202288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336966</th>\n",
       "      <td>336966</td>\n",
       "      <td>498</td>\n",
       "      <td>1122</td>\n",
       "      <td>4981122</td>\n",
       "      <td>1122498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337755</th>\n",
       "      <td>337755</td>\n",
       "      <td>182</td>\n",
       "      <td>18240</td>\n",
       "      <td>18218240</td>\n",
       "      <td>18240182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340509</th>\n",
       "      <td>340509</td>\n",
       "      <td>1728</td>\n",
       "      <td>11784</td>\n",
       "      <td>172811784</td>\n",
       "      <td>117841728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353199</th>\n",
       "      <td>353199</td>\n",
       "      <td>256</td>\n",
       "      <td>2551</td>\n",
       "      <td>2562551</td>\n",
       "      <td>2551256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pairId  FirstId  SecondId        col1        col2\n",
       "93524    93524     2255     18014   225518014   180142255\n",
       "107647  107647    10008     10404  1000810404  1040410008\n",
       "123152  123152     3505      8046    35058046    80463505\n",
       "123761  123761       19     16150     1916150     1615019\n",
       "124261  124261     5641      8046    56418046    80465641\n",
       "124903  124903     6107       235     6107235     2356107\n",
       "128879  128879    17602      2717   176022717   271717602\n",
       "133284  133284     1591      8217    15918217    82171591\n",
       "139487  139487      504      2799     5042799     2799504\n",
       "153763  153763      699      2994     6992994     2994699\n",
       "171167  171167     5494       996     5494996     9965494\n",
       "173304  173304     2741      6405    27416405    64052741\n",
       "194281  194281    24996       699    24996699    69924996\n",
       "201838  201838      765     18823    76518823    18823765\n",
       "212235  212235     1460     14578   146014578   145781460\n",
       "226778  226778     1980      8046    19808046    80461980\n",
       "229354  229354     2540      3795    25403795    37952540\n",
       "238033  238033     1420      8046    14208046    80461420\n",
       "239980  239980     2627     10404   262710404   104042627\n",
       "244528  244528     9217       353     9217353     3539217\n",
       "245781  245781    22953       819    22953819    81922953\n",
       "247753  247753     2094      8160    20948160    81602094\n",
       "256914  256914      332     10404    33210404    10404332\n",
       "268567  268567    15193       604    15193604    60415193\n",
       "277229  277229        7      7323       77323       73237\n",
       "277387  277387     2061     23019   206123019   230192061\n",
       "280690  280690     6957     10404   695710404   104046957\n",
       "282925  282925     1223      7915    12237915    79151223\n",
       "289264  289264     2563      2171    25632171    21712563\n",
       "289966  289966       29     25009     2925009     2500929\n",
       "291945  291945     4213       221     4213221     2214213\n",
       "300074  300074     2241      9618    22419618    96182241\n",
       "307799  307799    14231      9079   142319079   907914231\n",
       "309351  309351     5805       684     5805684     6845805\n",
       "310044  310044     6291     10404   629110404   104046291\n",
       "330339  330339     4155     10404   415510404   104044155\n",
       "336355  336355     2288     16120   228816120   161202288\n",
       "336966  336966      498      1122     4981122     1122498\n",
       "337755  337755      182     18240    18218240    18240182\n",
       "340509  340509     1728     11784   172811784   117841728\n",
       "353199  353199      256      2551     2562551     2551256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "test[test['col1'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we assumed the total number of pairs is much higher than the number of positive pairs, but it is not the case for the test set. It means that the test set is constructed not by sampling random pairs, but with a specific sampling algorithm. Pairs of class `1` are oversampled.\n",
    "\n",
    "Now think, how we can exploit this fact? What is the leak here? If you get it now, you may try to get to the final answer yourself, othewise you can follow the instructions below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a magic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a magic feature, that will solve the problem almost perfectly. The instructions will lead you to the correct solution, but please, try to explain the purpose of the steps we do to yourself -- it is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incidence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to build an [incidence matrix](https://en.wikipedia.org/wiki/Incidence_matrix). You can think of pairs `(FirstId, SecondId)` as of edges in an undirected graph. \n",
    "\n",
    "The incidence matrix is a matrix of size `(maxId + 1, maxId + 1)`, where each row (column) `i` corresponds `i-th` `Id`. In this matrix we put the value `1` to the position `[i, j]`, if and only if a pair `(i, j)` or `(j, i)` is present in  a given set of pais `(FirstId, SecondId)`. All the other elements in the incidence matrix are zeros.   \n",
    "\n",
    "**Important!** The incidence matrices are typically very very sparse (small number of non-zero values). At the same time incidence matrices are usually huge in terms of total number of elements, and it is **impossible to store them in memory in dense format**. But due to their sparsity incidence matrices **can be easily represented as sparse matrices**. If you are not familiar with sparse matrices, please see [wiki](https://en.wikipedia.org/wiki/Sparse_matrix) and [scipy.sparse reference](https://docs.scipy.org/doc/scipy/reference/sparse.html). Please, use any of `scipy.sparse` constructors to build incidence matrix. \n",
    "\n",
    "For example, you can use this constructor: `scipy.sparse.coo_matrix((data, (i, j)))`. We highly recommend to learn to use different `scipy.sparse` constuctors, and matrices types, but if you feel you don't want to use them, you can always build this matrix with a simple `for` loop. You will need first to create a matrix using `scipy.sparse.coo_matrix((M, N), [dtype])` with an appropriate shape `(M, N)` and then iterate through `(FirstId, SecondId)` pairs and fill corresponding elements in matrix with ones. \n",
    "\n",
    "**Note**, that the matrix should be symmetric and consist only of zeros and ones. It is a way to check yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Didn't quite understand this assignment until read this post, credit goes to: \n",
    "# https://www.coursera.org/learn/competitive-data-science/discussions/weeks/2/threads/aWwVDsG9EeeX-w6bGv5qMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427</td>\n",
       "      <td>8053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17044</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19237</td>\n",
       "      <td>20966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8005</td>\n",
       "      <td>20765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16837</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col1   col2\n",
       "0   1427   8053\n",
       "1  17044   7681\n",
       "2  19237  20966\n",
       "3   8005  20765\n",
       "4  16837    599"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First make a copy of FirstID and SecondID into x and y\n",
    "# Reason for doing this is NewID = FirstID + SecondID and NewID = SecondID + FirstID\n",
    "# No restriction that FirstID must be infront of SecondID\n",
    "x = test[['FirstId','SecondId']].rename(columns={'FirstId':'col1', 'SecondId':'col2'})\n",
    "y = test[['SecondId','FirstId']].rename(columns={'SecondId':'col1', 'FirstId':'col2'})\n",
    "\n",
    "# Next is to concatenate FirstID and SecondID and also drop the duplicated rows\n",
    "# keep = 'first' is used to keep the first occurrence\n",
    "test1 = pd.concat([x,y],ignore_index=True).drop_duplicates(keep='first')\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find test1 still has two columns but now for col1 and col2, \n",
    "# they both have FirstID and SecondID from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736872,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next is to create the matrix, but first let's create a vector with all ones in it, \n",
    "# the length of test1['col1'] as the vecotr length \n",
    "vec = np.ones(test1.col1.shape, dtype=int)\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coo_matrix((data, (i, j)), [shape=(M, N)])\n",
    "#    to construct from three arrays:\n",
    "#       data[:] the entries of the matrix, in any order\n",
    "#       i[:] the row indices of the matrix entries\n",
    "#       j[:] the column indices of the matrix entries\n",
    "# Where A[i[k], j[k]] = data[k]. When shape is not specified, it is inferred from the index arrays\n",
    "\n",
    "# Data here is the entries of the matrix, that's why we need to create a vector of ones\n",
    "# with size of test['col1'], actually length of col1 == col2\n",
    "# Such way, test1.col1 is i[:], test1.col2 is j[:], and inc_mat[i[k], j[k]] = vec[k] = 1 where k is length of 'col1'\n",
    "# By doing so, we have successfully marked the correlation between col1 and col2\n",
    "inc_mat = scipy.sparse.coo_matrix((vec, (test1.col1,test1.col2)), shape=(test1.col1.max() + 1, test1.col1.max() + 1))\n",
    "\n",
    "# Sanity checks\n",
    "assert inc_mat.max() == 1\n",
    "assert inc_mat.sum() == 736872"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient to have matrix in `csr` format eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_mat = inc_mat.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now build the magic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we build the incidence matrix? We can think of the rows in this matix as of representations for the objects. `i-th` row is a representation for an object with `Id = i`. Then, to measure similarity between two objects we can measure similarity between their representations. And we will see, that such representations are very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the rows from the incidence matrix, that correspond to `test.FirstId`'s, and `test.SecondId`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, scipy goes crazy if a matrix is indexed with pandas' series. \n",
    "# So do not forget to convert `pd.series` to `np.array`\n",
    "# These lines should normally run very quickly \n",
    "\n",
    "# Since First and second ID now represents row's number, then just select those rows\n",
    "rows_FirstId  = inc_mat[test.FirstId.values,:]\n",
    "rows_SecondId = inc_mat[test.SecondId.values,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our magic feature will be the *dot product* between representations of a pair of objects. Dot product can be regarded as similarity measure -- for our non-negative representations the dot product is close to 0 when the representations are different, and is huge, when representations are similar. \n",
    "\n",
    "Now compute dot product between corresponding rows in `rows_FirstId` and `rows_SecondId` matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368550,)\n"
     ]
    }
   ],
   "source": [
    "# Note, that in order to do pointwise multiplication in scipy.sparse you need to use function `multiply`\n",
    "# regular `*` corresponds to matrix-matrix multiplication\n",
    "\n",
    "f = rows_FirstId.multiply(rows_SecondId)\n",
    "\n",
    "# sum on each row and get the correct shape\n",
    "f = f.sum(axis=1)\n",
    "\n",
    "f = np.squeeze(np.asarray(f))\n",
    "\n",
    "print (f.shape)\n",
    "\n",
    "# Sanity check\n",
    "assert f.shape == (368550, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it! **We've built our magic feature.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From magic feature to binary predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we convert this feature into binary predictions? We do not have a train set to learn a model, but we have a piece of information about test set: the baseline accuracy score that you got, when submitting constant. And we also have a very strong considerations about the data generative process, so probably we will be fine even without a training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may try to choose a thresold, and set the predictions to 1, if the feature value `f` is higer than the threshold, and 0 otherwise. What threshold would you choose? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find a right threshold? Let's first examine this feature: print frequencies (or counts) of each value in the feature `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 15 19 20 21 28 35]\n"
     ]
    }
   ],
   "source": [
    "# For example use `np.unique` function, check for flags\n",
    "\n",
    "print(np.unique(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num = 14, frequency = 0.497298\n",
      "Num = 15, frequency = 0.002312\n",
      "Num = 19, frequency = 0.001481\n",
      "Num = 20, frequency = 0.498708\n",
      "Num = 21, frequency = 0.000016\n",
      "Num = 28, frequency = 0.000147\n",
      "Num = 35, frequency = 0.000038\n"
     ]
    }
   ],
   "source": [
    "for num in sorted(np.unique(f)):\n",
    "    print('Num = %i, frequency = %f' % (num, sum(f==num)/f.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see how this feature clusters the pairs? Maybe you can guess a good threshold by looking at the values? \n",
    "\n",
    "In fact, in other situations it can be not that obvious, but in general to pick a threshold you only need to remember the score of your baseline submission and use this information. Do you understand why and how?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a threshold below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = f > 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49890923890923888"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred)/f.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.loc[:,['pairId']]\n",
    "submission['Prediction'] = pred.astype(int)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now submit it to the grader! It is not possible to submit directly from this notebook, as we need to submit a `csv` file, not a single number (limitation of Coursera platform). \n",
    "\n",
    "To download `submission.csv` file that you've just produced <a href='./submission.csv'>click here</a> (if the link opens in browser, right-click on it and shoose \"Save link as\"). Then go to [assignment page](https://www.coursera.org/learn/competitive-data-science/programming/KsASv/data-leakages/submission) and submit your `.csv` file in 'My submission' tab.\n",
    "\n",
    "\n",
    "If you did everything right, the score should be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally:** try to explain to yourself, why the whole thing worked out. In fact, there is no magic in this feature, and the idea to use rows in the incidence matrix can be intuitively justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it is not the only leak in this dataset. There is another totally different way to get almost 100% accuracy. Try to find it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
